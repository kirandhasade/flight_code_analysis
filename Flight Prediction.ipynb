{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fbe9de",
   "metadata": {},
   "source": [
    "### Project Name: Flight Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f627fcb9",
   "metadata": {},
   "source": [
    "### Project Objective:\n",
    "##### The goal of this project is to analyse and clean the data so that we can use this to predict flight prices based on a variety of variables. The number of people who fly has dramatically increased in recent years. Pricing alters dynamically owing to many variables, making it difficult for airlines to maintain prices.As a result, we will attempt to solve this problem by cleaning and analysing the data which will be used by machine learning models in flight fare predictions.\n",
    "\n",
    "### Analysis Involve Phases:\n",
    "1. Data collection\n",
    "2. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c9f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0a07ab",
   "metadata": {},
   "source": [
    "### Data Collection/Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94586864",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"flight_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014658b0",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac044740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
       "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
       "       'Additional_Info', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ace8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'Airline':'airline', \n",
    "                         'Date_of_Journey': 'date_of_journey', \n",
    "                         'Source': 'source', \n",
    "                         'Destination': 'destination', \n",
    "                         'Route': 'route',\n",
    "                         'Dep_Time': 'dep_time', \n",
    "                         'Arrival_Time': 'arrival_time', \n",
    "                         'Duration':'duration', \n",
    "                         'Total_Stops': 'total_stops', \n",
    "                         'Additional_Info': 'additional_info',\n",
    "                         'Price': 'price' \n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61550df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13354 entries, 0 to 13353\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   airline          13354 non-null  object \n",
      " 1   date_of_journey  13354 non-null  object \n",
      " 2   source           13354 non-null  object \n",
      " 3   destination      13354 non-null  object \n",
      " 4   route            13353 non-null  object \n",
      " 5   dep_time         13354 non-null  object \n",
      " 6   arrival_time     13354 non-null  object \n",
      " 7   duration         13354 non-null  object \n",
      " 8   total_stops      13353 non-null  object \n",
      " 9   additional_info  13354 non-null  object \n",
      " 10  price            10683 non-null  float64\n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9531342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13354, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6379cfd6",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "- Number of variables = 11\n",
    "- Number of rows = 13354\n",
    "- Number of categorical type of feature = 10\n",
    "- Number of numerical type of feature = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81494ce",
   "metadata": {},
   "source": [
    "### Data Preparation/Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b132ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(dataframe):\n",
    "    \n",
    "    \n",
    "    # By using lambda function -  split date_of_journey into date, month & year\n",
    "    dataframe['Date']= dataframe['Date_of_Journey'].apply(lambda x:x.split(\"/\")[0])\n",
    "    dataframe['Month']= dataframe['Date_of_Journey'].apply(lambda x:x.split(\"/\")[1])\n",
    "    dataframe['Year']= dataframe['Date_of_Journey'].apply(lambda x:x.split(\"/\")[2])\n",
    "    \n",
    "    # or dataframe['Date']=dataframe['Date_of_Journey'].str.split('/').str[0]\n",
    "    # or dataframe['Date']=dataframe['Date_of_Journey'].str.split('/').str[0]\n",
    "    # or dataframe['Year']=dataframe['Date_of_Journey'].str.split('/').str[2]\n",
    "    \n",
    "    print(\"Split of date_of_journey - done\")\n",
    "    \n",
    "    # To convert date Month and Year column to integer\n",
    "    dataframe['Date']=dataframe['Date'].astype(int)\n",
    "    dataframe['Month']=dataframe['Month'].astype(int)\n",
    "    dataframe['Year']=dataframe['Year'].astype(int)\n",
    "    print(\"Convert date, month and year into integer - done\")\n",
    "    \n",
    "    # Dropping of Date_of_Journey column\n",
    "    dataframe.drop('Date_of_Journey',axis=1,inplace=True)\n",
    "    \n",
    "    # Splitting Arrival Time column\n",
    "    dataframe['Arrival_Time'].str.split(' ')\n",
    "    \n",
    "    # Here we have to focus on time not the date\n",
    "    \n",
    "    dataframe['Arrival_Time']=final_df['Arrival_Time'].apply(lambda x:x.split(' ')[0])\n",
    "    \n",
    "    # To split arrival time in hour and minutes\n",
    "    dataframe['Arrival_Hour']=dataframe['Arrival_Time'].str.split(':').str[0]\n",
    "    dataframe['Arrival_Min']=dataframe['Arrival_Time'].str.split(':').str[1]\n",
    "\n",
    "    # To change 'Arrival_Min' and 'Arrival_Hour' in integer Data type\n",
    "    dataframe['Arrival_Hour']=dataframe['Arrival_Hour'].astype(int)\n",
    "    dataframe['Arrival_Min']=dataframe['Arrival_Min'].astype(int)\n",
    "\n",
    "    # To drop Arrival_Time column\n",
    "    dataframe.drop('Arrival_Time',axis=1,inplace=True)\n",
    "\n",
    "    # To change Departure time by splitting time in hour and minutes\n",
    "\n",
    "    dataframe['Dept_Hour']=dataframe['Dep_Time'].str.split(':').str[0]\n",
    "    dataframe['Dept_Min']=dataframe['Dep_Time'].str.split(':').str[1]\n",
    "\n",
    "    # To change 'Dept_Hour' and 'Dept_min' in integer Data type\n",
    "    dataframe['Dept_Hour']=dataframe['Dept_Hour'].astype(int)\n",
    "    dataframe['Dept_Min']=dataframe['Dept_Min'].astype(int)\n",
    "\n",
    "    # To drop Dep_Time column\n",
    "    dataframe.drop('Dep_Time',axis=1,inplace=True)\n",
    "\n",
    "    # Splitting Hours  from Duration column\n",
    "    dataframe['Duration_hour']=dataframe['Duration'].str.split(' ').str[0].str.split('h').str[0]\n",
    "\n",
    "    # We have '5m' in our dataset\n",
    "    dataframe[final_df['Duration_hour']=='5m']\n",
    "\n",
    "     # Dropping 2 rows\n",
    "    dataframe.drop(6474,axis=0,inplace=True)\n",
    "    dataframe.drop(2660,axis=0,inplace=True)\n",
    "    # Above records are incorrect because Mumbai to Hyderabad it is showing as 5 minutes which is inconsitent or not correct hence we are dropping above 2 rows\n",
    "    \n",
    "     return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706080dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preperation(dataframe)\n",
    "   # Splitting Minutes from duration-(Data Preperation)\n",
    "     final_df['Duration_min']=final_df['Duration'].str.split(' ').str[1].str.split('m').str[0]\n",
    "        \n",
    "    # We have replaced Nan values with 0\n",
    "      final_df['Duration_min']=final_df['Duration_min'].fillna(0)\n",
    "        \n",
    "    # To check null values\n",
    "     final_df['Duration_min'].isnull().sum()\n",
    "        \n",
    "    # Dropping Duration column\n",
    "     final_df.drop('Duration',axis=1,inplace=True)\n",
    "        \n",
    "    # In route we have one Nan value to see which record is Nan we can use below code:\n",
    "     final_df[final_df['Total_Stops'].isnull()]\n",
    "        \n",
    "    # To analyse total stops column\n",
    "     final_df['Total_Stops'].unique()\n",
    "        \n",
    "    recode = {'non-stop':0,'1 stop':1,'2 stops':2,'3 stops':3,'4 stops':4, 'nan':1}\n",
    "   \n",
    "    final_df['Total_Stops'] = final_df['Total_Stops'].replace(recode)\n",
    "    \n",
    "    final_df['Total_Stops'].unique()\n",
    "    \n",
    "    # Filling Null values\n",
    "    final_df['Total_Stops'] = final_df['Total_Stops'].fillna(1)\n",
    "    \n",
    "    final_df['Total_Stops'].unique()\n",
    "    \n",
    "    # To drop Dep_Time column\n",
    "    final_df.drop('Route',axis=1,inplace=True)\n",
    "    \n",
    "    # To handle categorical variable\n",
    "    \n",
    "    # To check unique values in below columns\n",
    "    final_df['Airline'].unique()\n",
    "    final_df['Source'].unique()\n",
    "    final_df['Destination'].unique()\n",
    "    final_df['Additional_Info'].unique()\n",
    "    \n",
    "    # Here we can use label encoder for the above columns to convert categorical feature into numerical feature\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Create object of class LabelEncoder\n",
    "    labelencoder=LabelEncoder()\n",
    "    \n",
    "    final_df['Airline']=labelencoder.fit_transform(final_df['Airline'])\n",
    "    final_df['Source']=labelencoder.fit_transform(final_df['Source'])\n",
    "    final_df['Destination']=labelencoder.fit_transform(final_df['Destination'])\n",
    "    final_df['Additional_Info']=labelencoder.fit_transform(final_df['Additional_Info'])\n",
    "    \n",
    "    # Here we can see all columns are converted into object and float data type\n",
    "    final_df.info()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
